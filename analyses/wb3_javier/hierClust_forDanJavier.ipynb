{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import nibabel as nib \n",
    "from glob import glob \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import argparse\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "from numpy.testing import assert_array_almost_equal\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.datasets, sklearn.decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.cluster.hierarchy import cut_tree, fcluster, cophenet\n",
    "import imageio\n",
    "from scipy.spatial.distance import pdist \n",
    "from scipy.stats import spearmanr\n",
    "import nibabel as nib\n",
    "from scipy.cluster.hierarchy import inconsistent\n",
    "\n",
    "from sklearn.preprocessing import scale \n",
    "\n",
    "\n",
    "%autosave 5\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "def to_gif(filenames, saveas): \n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        images.append(imageio.imread(filename))\n",
    "    imageio.mimsave(saveas, images, duration=0.75 )\n",
    "\n",
    "\n",
    "def get_pcs(X_train, nComp=None, idComp=None): \n",
    "    # https://stats.stackexchange.com/questions/229092/how-to-reverse-pca-and-reconstruct-original-variables-from-several-principal-com\n",
    "    \n",
    "    #X = FEF_cat\n",
    "    #print(\"shape: \"+ str(X_train.shape))\n",
    "    \n",
    "    mu = np.mean(X_train, axis=0)\n",
    "\n",
    "    pca = sklearn.decomposition.PCA()\n",
    "    pca.fit(X_train)\n",
    "\n",
    "    if nComp != None: \n",
    "        #nComp = 2\n",
    "        X_projected = np.dot(pca.transform(X_train)[:,:nComp], pca.components_[:nComp,:])\n",
    "        X_projected += mu\n",
    "\n",
    "    elif idComp != None: \n",
    "        #idComp = 2\n",
    "        X_projected = np.dot(pca.transform(X_train)[:,idComp].reshape([ X_train.shape[0],1]), pca.components_[idComp,:].reshape([1, X_train.shape[1]]))\n",
    "        X_projected += mu\n",
    "\n",
    "\n",
    "    X_train_pca = pca.transform(X_train)[:,:nComp]\n",
    "    \n",
    "    exp_var = pca.explained_variance_ratio_[:nComp]\n",
    "\n",
    "    loss = np.sum((X_train - X_projected) ** 2, axis=1).mean()\n",
    "\n",
    "    #print(Xhat[0,])\n",
    "    #print(Xhat[0,].shape)\n",
    "    #print(Xhat.shape)\n",
    "    \n",
    "    \n",
    "    # return pcs, recon, loss, cumLoss, \n",
    "    return X_train_pca, X_projected, exp_var, loss\n",
    "\n",
    "def get_pcs_v2(X_train, nComp=None): \n",
    "    # https://stats.stackexchange.com/questions/229092/how-to-reverse-pca-and-reconstruct-original-variables-from-several-principal-com\n",
    "    \n",
    "    #print(\"shape: {}\".format(X_train.shape))\n",
    "    \n",
    "    # we need (TRs x Voxels)\n",
    "    assert(X_train.shape[0] == 180)\n",
    "    \n",
    "    \n",
    "    # create pca object\n",
    "    # nComp determines how many PCs we want ex. 10 \n",
    "    pca = sklearn.decomposition.PCA(n_components=nComp)\n",
    "\n",
    "    # X_train_pca is the nComp PCs ex. 10 \n",
    "    #  X_train_pca.shape == (180, 5)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    assert(X_train_pca.shape == (180,nComp) )\n",
    "    \n",
    "    \n",
    "    # X_projected is the PC projected back into signal space \n",
    "    X_projected = pca.inverse_transform(X_train_pca)\n",
    "    assert(X_projected.shape == X_train.shape)\n",
    "    \n",
    "    exp_var = pca.explained_variance_ratio_\n",
    "    assert(exp_var.shape == (nComp,))\n",
    "    \n",
    "    \n",
    "    loss = np.sum((X_train - X_projected) ** 2, axis=1).mean()\n",
    "\n",
    "    # returns\n",
    "    #   PCs\n",
    "    #   the PCs projected to singnal space (same dimensions as input data)\n",
    "    #   explained variance for each PC \n",
    "    #   loss    \n",
    "    return X_train_pca, X_projected, exp_var, loss\n",
    "\n",
    "\n",
    "def get_pcs_simple(X, nComp=None): \n",
    "    # https://stats.stackexchange.com/questions/229092/how-to-reverse-pca-and-reconstruct-original-variables-from-several-principal-com\n",
    "    # https://stackoverflow.com/questions/36566844/pca-projection-and-reconstruction-in-scikit-learn\n",
    "    \n",
    "    X.shape # (1848, 180) (Voxels, Timepoints)\n",
    "\n",
    "    #pca = sklearn.decomposition.PCA(n_components=10)\n",
    "    pca = sklearn.decomposition.PCA()\n",
    "\n",
    "    pca.fit(X) # \tFit the model with X.\n",
    "    \n",
    "    print(pca.explained_variance_ratio_)\n",
    "    \n",
    "    \n",
    "    data_pca = pca.transform(X) # Apply dimensionality reduction to X.\n",
    "    \n",
    "    \n",
    "    data_proj = pca.inverse_transform(X_train_pca)\n",
    "\n",
    "    \n",
    "    \n",
    "    return data_pca, Xhat, exp_var \n",
    "\n",
    "\n",
    "def get_pcs_tutorial(): \n",
    "    # https://stackoverflow.com/questions/36566844/pca-projection-and-reconstruction-in-scikit-learn\n",
    "    \n",
    "    from sklearn.decomposition import PCA\n",
    "    import numpy as np\n",
    "    from numpy.testing import assert_array_almost_equal\n",
    "    from sklearn.utils.extmath import svd_flip \n",
    "\n",
    "    n_comp = 30 \n",
    "\n",
    "    X_train = np.random.randn(100, 50)\n",
    "    #X_train = FEF_cat \n",
    "    \n",
    "    pca = PCA(n_components=n_comp)\n",
    "    pca.fit(X_train)\n",
    "\n",
    "    U, S, VT = np.linalg.svd(X_train - X_train.mean(0), full_matrices=False)\n",
    "    U, VT = svd_flip(U, VT)\n",
    "    assert_array_almost_equal(VT[:n_comp], pca.components_, decimal=2)\n",
    "\n",
    "    ## pca.transform calculates the loadings\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_train_pca2 = (X_train - pca.mean_).dot(pca.components_.T)\n",
    "    assert_array_almost_equal(X_train_pca, X_train_pca2)\n",
    "\n",
    "\n",
    "    ## pca.inverse_transform obtains the projection onto \n",
    "    ## components in signal space you are interested in\n",
    "    X_projected = pca.inverse_transform(X_train_pca)\n",
    "    X_projected2 = X_train_pca.dot(pca.components_) + pca.mean_\n",
    "    assert_array_almost_equal(X_projected, X_projected2)\n",
    "\n",
    "\n",
    "    ## You can now evaluate the projection loss\n",
    "    print(\"loss: {}\".format(np.sum((X_train - X_projected) ** 2, axis=1).mean()))\n",
    "    print(\"loss: {}\".format(np.sum((X_train - X_projected2) ** 2, axis=1).mean()))\n",
    "\n",
    "\n",
    "    ## SIMPLE \n",
    "    \n",
    "    #n_comp = 30 \n",
    "\n",
    "    #X_train = np.random.randn(100, 50)\n",
    "    X_train = FEF_cat.T\n",
    "    \n",
    "        \n",
    "    for n_comp in [0, 1, 2, 5, 10, 30, 50]:\n",
    "        \n",
    "        pca = PCA(n_components=n_comp)\n",
    "        pca.fit(X_train)\n",
    "\n",
    "        print(\"X_train.shape {}\".format(X_train.shape))\n",
    "        print(\"components.shape {}\".format(pca.components_.shape))\n",
    "        ## pca.transform calculates the loadings\n",
    "        X_train_pca = pca.transform(X_train)\n",
    "        print(\"loadings {}\".format(X_train_pca.shape))\n",
    "        \n",
    "        X_train_pca2 = pca.fit_transform(X_train)\n",
    "        print(\"loadings2 {}\".format(X_train_pca2.shape))\n",
    "\n",
    "        ## pca.inverse_transform obtains the projection onto \n",
    "        ## components in signal space you are interested in\n",
    "        X_projected = pca.inverse_transform(X_train_pca)\n",
    "\n",
    "        ## You can now evaluate the projection loss\n",
    "        print(\"loss: {}\".format(np.sum((X_train - X_projected) ** 2, axis=1).mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#work_dir=\"/data/NIMH_scratch/kleinrl/ds003216-download/derivatives/sub-02/VASO_fun2_afni\"\n",
    "work_dir=\"/data/NIMH_scratch/kleinrl/Shared/hierClust\"\n",
    "data_dir=work_dir+\"/data\"\n",
    "\n",
    "out_dir=work_dir+\"/out\"\n",
    "roi_dir=work_dir+\"/rois\"\n",
    "timeseries_maindir=work_dir+\"/timeseries\"\n",
    "plot_dir=work_dir+\"/plots\"\n",
    "\n",
    "img_path = work_dir+\"/misc/parc_hcp_kenshu_uthr.nii.gz\"\n",
    "img = nib.load(img_path)\n",
    "img_data = img.get_fdata()\n",
    "            \n",
    "\n",
    "sess = glob(timeseries_maindir+\"/VASO_grandmean_WITHOUT-ses-13_spc_despike\")\n",
    "sess+= glob(timeseries_maindir+\"/sub*_spc_despike\")\n",
    "#sess = sess[0:3]\n",
    "\n",
    "roi=\"FEF\"\n",
    "#types = [\"ward\"] #, \"centroid\", \"median\", \"weighted\", \"average\", \"complete\", \"single\" ]\n",
    "types = [\"ward\", \"centroid\", \"median\", \"weighted\", \"average\", \"complete\", \"single\" ]\n",
    "\n",
    "\n",
    "cophenet_coefs = []\n",
    "cophenet_coefs.append(['ses', 'type', 'i', 'corr_coef_sp', 'corr_coef_pe'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for ses in sess:\n",
    "#     for type in types: \n",
    "#         for i in [-1, 3, 5, 7 ]: #, 1, 2, 3, 4, 5, 6, 7]:#, 8, 9, 10, 11, 12, 15, 20, 25, 30]:\n",
    "\n",
    "#ses = sess[0] # grandmean \n",
    "ses = sess[1]  #  sub-02_ses-10_task-movie_run-02_VASO_spc_despike\n",
    "type = 'ward'\n",
    "i = 10 \n",
    "\n",
    "\n",
    "\n",
    "plot_file           = plot_dir+'/clust_'+type+\"_\"+str(i)+\"_\"+ses.split('/')[-1]+\"_\"+roi+\".jpeg\"    \n",
    "plot_file_hist      = plot_dir+'/hist_'+type+\"_\"+str(i)+\"_\"+ses.split('/')[-1]+\"_\"+roi+\".jpeg\"    \n",
    "plot_file_voxs      = plot_dir+'/voxs_'+type+\"_\"+str(i)+\"_\"+ses.split('/')[-1]+\"_\"+roi+\".jpeg\"    \n",
    "plot_nifti_clusters = data_dir+'/clustVoxs2_'+type+\"_\"+str(i)+\"_\"+ses.split('/')[-1]+\"_\"+roi+\".nii.gz\"  \n",
    "\n",
    "\n",
    "#ts_FEF_2D=glob(ses+\"/*\"+roi+\"*.2D\")\n",
    "ts_FEF_2D=glob(ses+\"/*\"+roi+\"*ijk.2D\")\n",
    "ts_FEF_2D.sort()\n",
    "\n",
    "print(ts_FEF_2D)\n",
    "\n",
    "FEF     = [ np.loadtxt(x) for x in ts_FEF_2D ] \n",
    "FEF_ind = np.concatenate([len(x)*[y+1] for x,y in zip(FEF, range(0,len(FEF))) ])\n",
    "FEF_cat = np.concatenate(FEF)\n",
    "\n",
    "FEF_ijk = FEF_cat[:,:3]\n",
    "FEF_cat = FEF_cat[:,3:]\n",
    "\n",
    "\n",
    "# SCALED? \n",
    "#X = scale(FEF_cat.T)\n",
    "\n",
    "X = FEF_cat.T\n",
    "X_T = X.T\n",
    "\n",
    "print(X.shape )\n",
    "print(X_T.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we generate the correlation map we use to cluster \n",
    "\n",
    "if i == -1\n",
    "    we just compute the pairwise correlations of voxels (1848 x 1848)\n",
    "\n",
    "if i != -1 \n",
    "    We get the PCs and reconstruct the voxel with i components\n",
    "    Uses the reconstructed voxels we compute the pairwise correlations for clustering (1848 x 1848)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "if i == -1: \n",
    "    print(\"corrs on orig data; i={} {}\".format(i, ses))\n",
    "    \n",
    "    # we use X_T (1848, 180) to get D=(1848,1848)\n",
    "    D = np.corrcoef(X_T)\n",
    "    \n",
    "\n",
    "\n",
    "else: \n",
    "    \n",
    "    print(\"corrs on recon data; i={} {}\".format(i, ses))\n",
    "    # we use X because get_pcas_v2 requires (TR, Voxels) (180,1848)\n",
    "    X_train_pca, X_projected, exp_var, loss       = get_pcs_v2(X, nComp=i)\n",
    "    \n",
    "    # rotate X_projected to get the pairwise correlations D=(1848,1848)\n",
    "    D = np.corrcoef(X_projected.T)\n",
    "    \n",
    "\n",
    "print(D.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "size=(12,12)\n",
    "fig = pylab.figure(figsize=size)\n",
    "plt.title(plot_file.split('/')[-1])\n",
    "\n",
    "\n",
    "axdendro = fig.add_axes([0.09,0.1,0.2,0.8])\n",
    "Y = sch.linkage(D, method=type)\n",
    "Z = sch.dendrogram(Y, orientation='right')\n",
    "\n",
    "\n",
    "axdendro.set_xticks([])\n",
    "axdendro.set_yticks([])\n",
    "axmatrix = fig.add_axes([0.3,0.1,0.6,0.8])\n",
    "\n",
    "index  = Z['leaves']\n",
    "\n",
    "D_sorted = D[index,:]\n",
    "D_sorted = D[:,index]\n",
    "\n",
    "im = axmatrix.matshow(D_sorted, aspect='auto', origin='lower')\n",
    "\n",
    "axmatrix.set_xticks([])\n",
    "axmatrix.set_yticks([])\n",
    "axcolor = fig.add_axes([0.91,0.1,0.02,0.8])\n",
    "pylab.colorbar(im, cax=axcolor)\n",
    "fig.show()\n",
    "plt.savefig(plot_file)\n",
    "#plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the Cophenetic Coefficient \n",
    "\n",
    "compares the linkage Y against the correlation matrix \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cophe_dists = cophenet(Y)\n",
    "\n",
    "orig_dists = pdist(D, metric='euclidean')\n",
    "\n",
    "assert(cophe_dists == orig_dists )\n",
    "print(cophe_dists.shape, orig_dists.shape)\n",
    "\n",
    "\n",
    "corr_coef_sp = spearmanr(orig_dists, cophe_dists)[0]\n",
    "corr_coef_pe = np.corrcoef(orig_dists, cophe_dists)[0,1]\n",
    "\n",
    "print(\"Cophenetic Coef - type:{}   i:{}    spearman: {}   pearson: {}\".format(type, i, corr_coef_sp, corr_coef_pe))\n",
    "\n",
    "\n",
    "#cophenet_coefs.append([ses, type, i, corr_coef_sp[0], corr_coef_pe])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "index               = Z['leaves']\n",
    "colors              = Z['color_list']        \n",
    "\n",
    "####################\n",
    "### color_list   - represents color of linkages not 1 to 1 with voxels? \n",
    "######################\n",
    "color_list          = colors + [colors[-1]]\n",
    "\n",
    "index_array = np.array(index)\n",
    "\n",
    "\n",
    "\n",
    "X_sorted        = X[:, index]\n",
    "X_T_sorted      = X_T[index, :]\n",
    "\n",
    "FEF_ijk_sorted  = FEF_ijk[index,:]\n",
    "FEF_ind_sorted  = FEF_ind[index]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chart = []\n",
    "to_plot = []\n",
    "to_plot_labs =[]\n",
    "voxs_by_color = []\n",
    "voxs_by_color_inds = []\n",
    "vox_by_color = []\n",
    "\n",
    "ijk_coords = []\n",
    "ijk_coords_lab = []\n",
    "\n",
    "for u in np.unique(color_list): \n",
    "    ind_color       = np.isin(color_list, u)\n",
    "    ind_color_where = np.where(ind_color)[0]\n",
    "    \n",
    "    lay_counts = FEF_ind_sorted[ind_color]\n",
    "    to_plot.append(lay_counts)\n",
    "\n",
    "    \n",
    "    ijk_coord = FEF_ijk_sorted[ind_color,:]\n",
    "    ijk_coords.append(ijk_coord)\n",
    "    \n",
    "\n",
    "    vox_by_color_ind = index_array[ind_color_where]\n",
    "    vox_by_color.append(X_sorted[:,ind_color_where])\n",
    "\n",
    "    ijk_coords_lab.append(u)\n",
    "    to_plot_labs.append(u)\n",
    "    \n",
    "    for uu in range(8):\n",
    "        ind = np.where(lay_counts == uu)[0]\n",
    "        \n",
    "        #print(\"{}    {}    {}    {}\".format(u, uu,len(ind[0]),  len(ind[0])/len(ind_color)*100))\n",
    "        chart.append([u, uu,len(ind),  len(ind)/len(ind_color)*100])\n",
    "\n",
    "chart = pd.DataFrame(chart)\n",
    "print(chart)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the NIFTI with cluster \n",
    "\n",
    "out_data = np.zeros(shape=img_data.shape)\n",
    "\n",
    "c_count = 1 \n",
    "for ijk_clust in ijk_coords:\n",
    "    for ijk_ind in ijk_clust:\n",
    "        ijk_ind = ijk_ind.astype(int)\n",
    "        out_data[ijk_ind[0],ijk_ind[1], ijk_ind[2]] = c_count \n",
    "        \n",
    "    c_count += 1 \n",
    "\n",
    "clipped_img = nib.Nifti1Image(out_data, img.affine, img.header)\n",
    "\n",
    "nib.save(clipped_img, plot_nifti_clusters)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# HIST PLOTS \n",
    "fig = pylab.figure(figsize=size)\n",
    "plt.hist(to_plot, 7, label=to_plot_labs, histtype='bar', stacked=False, fill=True)\n",
    "plt.legend(prop={'size': 10})\n",
    "plt.title(plot_file.split('/')[-1])\n",
    "plt.savefig(plot_file_hist)\n",
    "#plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# VOX PLOTS \n",
    "fig = pylab.figure(figsize=size)\n",
    "p = []\n",
    "for i_vox in range(len(vox_by_color)):\n",
    "    voxs    = vox_by_color[i_vox].T\n",
    "    mu      = np.mean(voxs, axis=0)\n",
    "    stdev   = np.std(voxs, axis=0)\n",
    "    \n",
    "    plt.plot(mu, label=to_plot_labs[i_vox])\n",
    "    plt.fill_between(range(mu.shape[0]),mu-stdev,mu+stdev,alpha=.1)\n",
    "\n",
    "plt.legend(loc=\"upper right\") #p, to_plot_labs, prop={'size': 10}\n",
    "plt.title(plot_file.split('/')[-1])\n",
    "plt.savefig(plot_file_voxs)\n",
    "#plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "FEF_cat_sorted = FEF_cat[index]\n",
    "\n",
    "rois2 = [   \n",
    "            # \"L_V1\",\n",
    "            # \"L_V2\",\n",
    "            # \"L_V3\",\n",
    "            # \"L_V4\",\n",
    "            # #\"L_FST\",\n",
    "            # \"L_PH\",\n",
    "            # \"L_MS\",\n",
    "            # \"L_LO3\",\n",
    "            # \"L_MT\",\n",
    "            # \"L_V4t\",\n",
    "            # \"L_MST\",\n",
    "            # \"L_VIP\",\n",
    "            # \"L_VIP\",\n",
    "                                    \n",
    "            \"L_LIPv\",\n",
    "            \"L_LIPd\",\n",
    "\n",
    "            # \"L_7Pm\",\n",
    "            # \"L_7m\",\n",
    "            # \"L_7AL\",\n",
    "            # \"L_7Am\",\n",
    "            # \"L_7PL\",\n",
    "            # \"L_7PC\",\n",
    "            ]\n",
    "\n",
    "for roi2 in rois2:\n",
    "\n",
    "    ts_ROI2_2D=glob(ses+\"/*\"+roi2+\"*ijk.2D\")\n",
    "    ts_ROI2_2D.sort()\n",
    "\n",
    "    ROI2     = [ np.loadtxt(x) for x in ts_ROI2_2D ] \n",
    "    ROI2_ind = np.concatenate([len(x)*[y+1] for x,y in zip(ROI2, range(0,len(ROI2))) ])\n",
    "    ROI2_cat = np.concatenate(ROI2)\n",
    "    \n",
    "    ROI2_ijk = ROI2_cat[:,:3]\n",
    "    ROI2_cat = ROI2_cat[:,3:]\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    plot_file_corr = plot_dir+'/corr_'+roi2+\"_\"+type+\"_\"+str(i)+\"_\"+ses.split('/')[-1]+\"_\"+roi+\".jpeg\"    \n",
    "    cat = np.concatenate([FEF_cat_sorted, ROI2_cat])\n",
    "    c = np.corrcoef(cat)\n",
    "    fig = pylab.figure(figsize=size)\n",
    "    p = plt.imshow(c)\n",
    "    fig.colorbar(p)\n",
    "    plt.title(plot_file.split('/')[-1])\n",
    "    plt.savefig(plot_file_corr)\n",
    "    #plt.close()\n",
    "\n",
    "    \n",
    "    plot_file_corr_single = plot_dir+'/corrSingle_'+roi2+\"_\"+type+\"_\"+str(i)+\"_\"+ses.split('/')[-1]+\"_\"+roi+\".jpeg\"    \n",
    "    len_x=FEF_cat_sorted.shape[0]\n",
    "    len_y=ROI2_cat.shape[0]\n",
    "    cc = c[:len_x,len_x:]\n",
    "    fig = pylab.figure(figsize=size)\n",
    "    p = plt.imshow(cc)\n",
    "    fig.colorbar(p)\n",
    "    plt.title(plot_file.split('/')[-1])\n",
    "    plt.savefig(plot_file_corr_single)\n",
    "    #plt.close()\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for ses in sess:\n",
    "#     for type in types: \n",
    "#         for i in [-1, 3, 5, 7 ]: #, 1, 2, 3, 4, 5, 6, 7]:#, 8, 9, 10, 11, 12, 15, 20, 25, 30]:\n",
    "\n",
    "\n",
    "#             plot_file           = plot_dir+'/clust_'+type+\"_\"+str(i)+\"_\"+ses.split('/')[-1]+\"_\"+roi+\".jpeg\"    \n",
    "#             plot_file_hist      = plot_dir+'/hist_'+type+\"_\"+str(i)+\"_\"+ses.split('/')[-1]+\"_\"+roi+\".jpeg\"    \n",
    "#             plot_file_voxs      = plot_dir+'/voxs_'+type+\"_\"+str(i)+\"_\"+ses.split('/')[-1]+\"_\"+roi+\".jpeg\"    \n",
    "#             plot_nifti_clusters = data_dir+'/clustVoxs2_'+type+\"_\"+str(i)+\"_\"+ses.split('/')[-1]+\"_\"+roi+\".nii.gz\"  \n",
    "\n",
    "\n",
    "#             #ts_FEF_2D=glob(ses+\"/*\"+roi+\"*.2D\")\n",
    "#             ts_FEF_2D=glob(ses+\"/*\"+roi+\"*ijk.2D\")\n",
    "#             ts_FEF_1D=glob(ses+\"/*\"+roi+\"*.1D\")\n",
    "            \n",
    "#             ts_FEF_2D.sort()\n",
    "#             ts_FEF_1D.sort()\n",
    "\n",
    "\n",
    "#             FEF     = [ np.loadtxt(x) for x in ts_FEF_2D ] \n",
    "#             FEF_ind = np.concatenate([len(x)*[y+1] for x,y in zip(FEF, range(0,len(FEF))) ])\n",
    "#             FEF_cat = np.concatenate(FEF)\n",
    "\n",
    "#             FEF_ijk = FEF_cat[:,:3]\n",
    "#             FEF_cat = FEF_cat[:,3:]\n",
    "\n",
    "#             #X = scale(FEF_cat.T)\n",
    "#             X = FEF_cat.T\n",
    "#             X_T = X.T\n",
    "            \n",
    "\n",
    "#             if i == -1: \n",
    "#                 D = np.corrcoef(X_T)\n",
    "#                 D_pdist = pdist(X_T)\n",
    "#             else: \n",
    "\n",
    "#                 #X_train_pca, X_projected, exp_var, loss       = get_pcs(X, nComp=i)\n",
    "#                 X_train_pca, X_projected, exp_var, loss       = get_pcs_v2(X, nComp=i)\n",
    "#                 #X_train_pca, X_projected, exp_var, loss       = get_pcs_v2(FEF_cat.T, nComp=i)\n",
    "\n",
    "\n",
    "#                 D = np.corrcoef(X_projected.T)\n",
    "#                 D_pdist = pdist(X_projected.T)\n",
    "\n",
    "\n",
    "#             len_rois = D.shape[0]\n",
    "\n",
    "\n",
    "#             size=(12,12)\n",
    "#             fig = pylab.figure(figsize=size)\n",
    "#             plt.title(plot_file.split('/')[-1])\n",
    "\n",
    "\n",
    "#             axdendro = fig.add_axes([0.09,0.1,0.2,0.8])\n",
    "#             Y = sch.linkage(D, method=type)\n",
    "#             Z = sch.dendrogram(Y, orientation='right')\n",
    "\n",
    "\n",
    "#             cophe_dists = cophenet(Y)\n",
    "#             #orig_dists = pdist(D, metric='cityblock')#'euclidean')\n",
    "#             orig_dists = pdist(D, metric='euclidean')\n",
    "\n",
    "\n",
    "#             corr_coef_sp = spearmanr(orig_dists, cophe_dists)\n",
    "#             corr_coef_pe = np.corrcoef(orig_dists, cophe_dists)[0,1]\n",
    "            \n",
    "#             print(\"{}   {}    {}   {}\".format(type, i, corr_coef_sp[0], corr_coef_pe))\n",
    "\n",
    "            \n",
    "#             cophenet_coefs.append([ses, type, i, corr_coef_sp[0], corr_coef_pe])\n",
    "            \n",
    "\n",
    "\n",
    "#             index               = Z['leaves']\n",
    "#             colors              = Z['color_list']            \n",
    "#             color_list          = colors + [colors[-1]]\n",
    "            \n",
    "#             index_array = np.array(index)\n",
    "            \n",
    "#             X_sorted        = X[:, index]\n",
    "#             X_T_sorted      = X_T[index, :]\n",
    "            \n",
    "#             FEF_ijk_sorted  = FEF_ijk[index,:]\n",
    "#             FEF_ind_sorted  = FEF_ind[index]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             chart = []\n",
    "#             to_plot = []\n",
    "#             to_plot_labs =[]\n",
    "#             voxs_by_color = []\n",
    "#             voxs_by_color_inds = []\n",
    "#             vox_by_color = []\n",
    "            \n",
    "#             ijk_coords = []\n",
    "#             ijk_coords_lab = []\n",
    "            \n",
    "#             for u in np.unique(color_list): \n",
    "#                 ind_color       = np.isin(color_list, u)\n",
    "#                 ind_color_where = np.where(ind_color)[0]\n",
    "                \n",
    "#                 lay_counts = FEF_ind_sorted[ind_color]\n",
    "#                 to_plot.append(lay_counts)\n",
    "\n",
    "                \n",
    "#                 ijk_coord = FEF_ijk_sorted[ind_color,:]\n",
    "#                 ijk_coords.append(ijk_coord)\n",
    "                \n",
    "\n",
    "\n",
    "#                 vox_by_color_ind = index_array[ind_color_where]\n",
    "\n",
    "#                 vox_by_color.append(X_sorted[:,ind_color_where])\n",
    "\n",
    "#                 ijk_coords_lab.append(u)\n",
    "#                 to_plot_labs.append(u)\n",
    "                \n",
    "#                 for uu in range(8):\n",
    "#                     ind = np.where(lay_counts == uu)[0]\n",
    "                    \n",
    "#                     #print(\"{}    {}    {}    {}\".format(u, uu,len(ind[0]),  len(ind[0])/len(ind_color)*100))\n",
    "#                     chart.append([u, uu,len(ind),  len(ind)/len(ind_color)*100])\n",
    "\n",
    "#             chart = pd.DataFrame(chart)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             out_data = np.zeros(shape=img_data.shape)\n",
    "\n",
    "#             c_count = 1 \n",
    "#             for ijk_clust in ijk_coords:\n",
    "#                 for ijk_ind in ijk_clust:\n",
    "#                     ijk_ind = ijk_ind.astype(int)\n",
    "#                     out_data[ijk_ind[0],ijk_ind[1], ijk_ind[2]] = c_count \n",
    "                    \n",
    "#                 c_count += 1 \n",
    "            \n",
    "#             clipped_img = nib.Nifti1Image(out_data, img.affine, img.header)\n",
    "            \n",
    "#             nib.save(clipped_img, plot_nifti_clusters)\n",
    "            \n",
    "            \n",
    "\n",
    "#             #labels_reorg = ids \n",
    "\n",
    "#             axdendro.set_xticks([])\n",
    "#             axdendro.set_yticks([])\n",
    "#             axmatrix = fig.add_axes([0.3,0.1,0.6,0.8])\n",
    "            \n",
    "#             D = D[index,:]\n",
    "#             D = D[:,index]\n",
    "\n",
    "#             im = axmatrix.matshow(D, aspect='auto', origin='lower')\n",
    "            \n",
    "#             axmatrix.set_xticks([])\n",
    "#             axmatrix.set_yticks([])\n",
    "#             axcolor = fig.add_axes([0.91,0.1,0.02,0.8])\n",
    "#             pylab.colorbar(im, cax=axcolor)\n",
    "#             fig.show()\n",
    "#             plt.savefig(plot_file)\n",
    "#             plt.close()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             # HIST PLOTS \n",
    "#             fig = pylab.figure(figsize=size)\n",
    "#             plt.hist(to_plot, 7, label=to_plot_labs, histtype='bar', stacked=False, fill=True)\n",
    "#             plt.legend(prop={'size': 10})\n",
    "#             plt.title(plot_file.split('/')[-1])\n",
    "#             plt.savefig(plot_file_hist)\n",
    "#             plt.close()\n",
    "\n",
    "\n",
    "\n",
    "#             # VOX PLOTS \n",
    "#             fig = pylab.figure(figsize=size)\n",
    "#             p = []\n",
    "#             for i_vox in range(len(vox_by_color)):\n",
    "#                 voxs    = vox_by_color[i_vox].T\n",
    "#                 mu      = np.mean(voxs, axis=0)\n",
    "#                 stdev   = np.std(voxs, axis=0)\n",
    "                \n",
    "#                 plt.plot(mu, label=to_plot_labs[i_vox])\n",
    "#                 plt.fill_between(range(mu.shape[0]),mu-stdev,mu+stdev,alpha=.1)\n",
    "\n",
    "#             plt.legend(loc=\"upper right\") #p, to_plot_labs, prop={'size': 10}\n",
    "#             plt.title(plot_file.split('/')[-1])\n",
    "#             plt.savefig(plot_file_voxs)\n",
    "#             plt.close()\n",
    "\n",
    "            \n",
    "#             FEF_cat_sorted = FEF_cat[index]\n",
    "            \n",
    "#             rois2 = [   \"L_V1\",\n",
    "#                         \"L_V2\",\n",
    "#                         \"L_V3\",\n",
    "#                         \"L_V4\",\n",
    "#                         #\"L_FST\",\n",
    "#                         \"L_PH\",\n",
    "#                         \"L_MS\",\n",
    "#                         \"L_LO3\",\n",
    "#                         \"L_MT\",\n",
    "#                         \"L_V4t\",\n",
    "#                         \"L_MST\",\n",
    "#                         \"L_VIP\",\n",
    "#                         \"L_VIP\",\n",
    "                                                \n",
    "#                         \"L_LIPv\",\n",
    "#                         \"L_LIPd\",\n",
    "\n",
    "#                         \"L_7Pm\",\n",
    "#                         \"L_7m\",\n",
    "#                         \"L_7AL\",\n",
    "#                         \"L_7Am\",\n",
    "#                         \"L_7PL\",\n",
    "#                         \"L_7PC\",\n",
    "#                         ]\n",
    "            \n",
    "#             for roi2 in rois2:\n",
    "            \n",
    "#                 ts_ROI2_2D=glob(ses+\"/*\"+roi2+\"*ijk.2D\")\n",
    "#                 ts_ROI2_1D=glob(ses+\"/*\"+roi2+\"*.1D\")\n",
    "#                 ts_ROI2_2D.sort()\n",
    "#                 ts_ROI2_1D.sort()\n",
    "\n",
    "#                 ROI2     = [ np.loadtxt(x) for x in ts_ROI2_2D ] \n",
    "#                 ROI2_ind = np.concatenate([len(x)*[y+1] for x,y in zip(ROI2, range(0,len(ROI2))) ])\n",
    "#                 ROI2_cat = np.concatenate(ROI2)\n",
    "                \n",
    "        \n",
    "\n",
    "#                 ROI2_ijk = ROI2_cat[:,:3]\n",
    "#                 ROI2_cat = ROI2_cat[:,3:]\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "#                 plot_file_corr = plot_dir+'/corr_'+roi2+\"_\"+type+\"_\"+str(i)+\"_\"+ses.split('/')[-1]+\"_\"+roi+\".jpeg\"    \n",
    "#                 cat = np.concatenate([FEF_cat_sorted, ROI2_cat])\n",
    "#                 c = np.corrcoef(cat)\n",
    "#                 fig = pylab.figure(figsize=size)\n",
    "#                 p = plt.imshow(c)\n",
    "#                 fig.colorbar(p)\n",
    "#                 plt.title(plot_file.split('/')[-1])\n",
    "#                 plt.savefig(plot_file_corr)\n",
    "#                 plt.close()\n",
    "\n",
    "                \n",
    "                \n",
    "#                 # SINGLE COMP \n",
    "#                 plot_file_corr_single = plot_dir+'/corrSingle_'+roi2+\"_\"+type+\"_\"+str(i)+\"_\"+ses.split('/')[-1]+\"_\"+roi+\".jpeg\"    \n",
    "#                 len_x=FEF_cat_sorted.shape[0]\n",
    "#                 len_y=ROI2_cat.shape[0]\n",
    "#                 cc = c[:len_x,len_x:]\n",
    "#                 fig = pylab.figure(figsize=size)\n",
    "#                 p = plt.imshow(cc)\n",
    "#                 fig.colorbar(p)\n",
    "#                 plt.title(plot_file.split('/')[-1])\n",
    "#                 plt.savefig(plot_file_corr_single)\n",
    "#                 plt.close()\n",
    "            \n",
    "#             print(type, ses,i)\n",
    "            \n",
    "            \n",
    "            \n",
    "#     filenames=glob(plot_dir+\"/clust*\"+type+\"_\"+str(i)+\"_*FEF.jpeg\")\n",
    "#     saveas=plot_dir+\"/clust_\"+type+\"_\"+str(i)+\"_FEF.gif\"\n",
    "#     to_gif(filenames, saveas)      \n",
    "                \n",
    "#     filenames=glob(plot_dir+\"/hist*\"+type+\"_\"+str(i)+\"_*FEF.jpeg\")\n",
    "#     saveas=plot_dir+\"/hist_\"+type+\"_\"+str(i)+\"_FEF.gif\"\n",
    "#     to_gif(filenames, saveas)      \n",
    "            \n",
    "#     filenames=glob(plot_dir+\"/voxs*\"+type+\"_\"+str(i)+\"_*FEF.jpeg\")\n",
    "#     saveas=plot_dir+\"/voxs_\"+type+\"_\"+str(i)+\"_FEF.gif\"\n",
    "#     to_gif(filenames, saveas)      \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
